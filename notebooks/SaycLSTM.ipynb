{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from batcher import Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./X_train.npy')\n",
    "y_train = np.load('./y_train.npy')\n",
    "\n",
    "X_val = np.load('./X_val.npy')\n",
    "y_val = np.load('./y_val.npy')\n",
    "\n",
    "n_examples = y_train.shape[0]\n",
    "n_time_steps = y_train.shape[1]\n",
    "n_ftrs = X_train.shape[2]\n",
    "n_bids = y_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 4, 179, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_examples, n_time_steps, n_ftrs, n_bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_size = 64\n",
    "n_layers = 3\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "cells = []\n",
    "for _ in range(n_layers):\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        tf.nn.rnn_cell.BasicLSTMCell(lstm_size),\n",
    "        output_keep_prob=keep_prob\n",
    "    )\n",
    "    cells.append(cell)\n",
    "    \n",
    "lstm_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "seq_in = tf.placeholder(tf.float32, [None, None, n_ftrs], 'seq_in')\n",
    "seq_out = tf.placeholder(tf.float32, [None, None, n_bids], 'seq_out')\n",
    "\n",
    "softmax_w = tf.get_variable('softmax_w', shape=[lstm_cell.output_size, n_bids], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer(seed=1337))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_rnn, _ = tf.nn.dynamic_rnn(lstm_cell, seq_in, initial_state=lstm_cell.zero_state(batch_size, dtype=tf.float32))\n",
    "out_rnn, _ = tf.nn.dynamic_rnn(lstm_cell, seq_in, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_bid_logit = tf.matmul(tf.reshape(out_rnn, [-1, lstm_size]), softmax_w, name='out_bid_logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_bid_target = tf.reshape(seq_out, [-1, n_bids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.losses.softmax_cross_entropy(out_bid_target, out_bid_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_step = tf.train.MomentumOptimizer(learning_rate=0.001, momentum=0.9).minimize(cost)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batcher(n_examples, batch_size)\n",
    "cost_batch = Batcher(n_examples, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. c_train=3.6880698204040527 c_valid=3.688000440597534\n",
      "1000. c_train=0.7143563628196716 c_valid=0.7177790999412537\n",
      "2000. c_train=0.6318325400352478 c_valid=0.6299329400062561\n",
      "3000. c_train=0.5171809792518616 c_valid=0.5199329853057861\n",
      "4000. c_train=0.45557910203933716 c_valid=0.45627012848854065\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    x_batch, y_batch = batch.next_batch([X_train, y_train])\n",
    "    if i % 1000 == 0:\n",
    "        x_cost, y_cost = cost_batch.next_batch([X_train, y_train])\n",
    "        c_train = sess.run(cost, feed_dict={seq_in: x_cost, seq_out: y_cost, keep_prob: 1.0})\n",
    "        c_valid = sess.run(cost, feed_dict={seq_in: X_val, seq_out: y_val, keep_prob: 1.0})\n",
    "        print('{}. c_train={} c_valid={}'.format(i, c_train, c_valid))\n",
    "    sess.run(train_step, feed_dict={seq_in: x_batch, seq_out: y_batch, keep_prob: 0.6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/test'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'model/test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
